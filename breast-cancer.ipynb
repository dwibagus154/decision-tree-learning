{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca90635-0662-4d2e-91e3-7dd4117ab803",
   "metadata": {},
   "source": [
    "# Tugas Kecil 1 IF3270 Pembelajaran Mesin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b109e0f-1017-48e0-80fc-c79c61ef02c9",
   "metadata": {},
   "source": [
    "### Anggota Kelompok\n",
    "### - 13519057 Kadek Dwi Bagus\n",
    "### - 13519217 Hughie Alghaniyyu Emiliano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b0ca6-7dcb-4d3c-9c6d-069b570354b4",
   "metadata": {},
   "source": [
    "#### Import Dataset Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c787477-08c8-4a2e-8e50-a34076910b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension    Species  \n",
       "0                  0.2654          0.4601                  0.11890  malignant  \n",
       "1                  0.1860          0.2750                  0.08902  malignant  \n",
       "2                  0.2430          0.3613                  0.08758  malignant  \n",
       "3                  0.2575          0.6638                  0.17300  malignant  \n",
       "4                  0.1625          0.2364                  0.07678  malignant  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115  malignant  \n",
       "565                0.1628          0.2572                  0.06637  malignant  \n",
       "566                0.1418          0.2218                  0.07820  malignant  \n",
       "567                0.2650          0.4087                  0.12400  malignant  \n",
       "568                0.0000          0.2871                  0.07039     benign  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "df = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names).assign(Species=breast_cancer_data['target_names'][breast_cancer_data.target])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cda95-7afc-4dc9-8ea9-34c88a9f8202",
   "metadata": {},
   "source": [
    "#### Split Dataset to 80% for Training and 20% for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3aee46-69a7-46df-9998-1b2fc10141ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of training data : 455 (79.96%)\n",
      "Amount of testing data  : 114 (20.04%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names)\n",
    "result = breast_cancer_data.target\n",
    "train_data, test_data, train_result, test_result = train_test_split(data, result, test_size=0.20)\n",
    "\n",
    "train_percentage = round((train_data.shape[0] / (train_data.shape[0] + test_data.shape[0])) * 100, 2)\n",
    "print(f\"Amount of training data : {train_data.shape[0]} ({train_percentage}%)\")\n",
    "\n",
    "test_percentage = round((test_data.shape[0] / (train_data.shape[0] + test_data.shape[0])) * 100, 2)\n",
    "print(f\"Amount of testing data  : {test_data.shape[0]} ({test_percentage}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd4e22-5e49-40fa-924a-46c0e71ec100",
   "metadata": {},
   "source": [
    "##### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61e6e14-c70b-42c4-a32d-38ecbd949572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>15.500</td>\n",
       "      <td>21.08</td>\n",
       "      <td>102.90</td>\n",
       "      <td>803.1</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.15710</td>\n",
       "      <td>0.15220</td>\n",
       "      <td>0.084810</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.06864</td>\n",
       "      <td>...</td>\n",
       "      <td>23.17</td>\n",
       "      <td>27.65</td>\n",
       "      <td>157.10</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.4002</td>\n",
       "      <td>0.42110</td>\n",
       "      <td>0.21340</td>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14.250</td>\n",
       "      <td>21.72</td>\n",
       "      <td>93.63</td>\n",
       "      <td>633.0</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.10980</td>\n",
       "      <td>0.13190</td>\n",
       "      <td>0.055980</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.06125</td>\n",
       "      <td>...</td>\n",
       "      <td>15.89</td>\n",
       "      <td>30.36</td>\n",
       "      <td>116.20</td>\n",
       "      <td>799.6</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.4238</td>\n",
       "      <td>0.51860</td>\n",
       "      <td>0.14470</td>\n",
       "      <td>0.3591</td>\n",
       "      <td>0.10140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>9.668</td>\n",
       "      <td>18.10</td>\n",
       "      <td>61.06</td>\n",
       "      <td>286.3</td>\n",
       "      <td>0.08311</td>\n",
       "      <td>0.05428</td>\n",
       "      <td>0.01479</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.06412</td>\n",
       "      <td>...</td>\n",
       "      <td>11.15</td>\n",
       "      <td>24.62</td>\n",
       "      <td>71.11</td>\n",
       "      <td>380.2</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.06409</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.3057</td>\n",
       "      <td>0.07875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>13.590</td>\n",
       "      <td>21.84</td>\n",
       "      <td>87.16</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.07956</td>\n",
       "      <td>0.08259</td>\n",
       "      <td>0.04072</td>\n",
       "      <td>0.021420</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.05859</td>\n",
       "      <td>...</td>\n",
       "      <td>14.80</td>\n",
       "      <td>30.04</td>\n",
       "      <td>97.66</td>\n",
       "      <td>661.5</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.14530</td>\n",
       "      <td>0.06189</td>\n",
       "      <td>0.2446</td>\n",
       "      <td>0.07024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>14.020</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.026520</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.05586</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>12.670</td>\n",
       "      <td>17.30</td>\n",
       "      <td>81.25</td>\n",
       "      <td>489.9</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.07664</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.1707</td>\n",
       "      <td>0.05984</td>\n",
       "      <td>...</td>\n",
       "      <td>13.71</td>\n",
       "      <td>21.10</td>\n",
       "      <td>88.70</td>\n",
       "      <td>574.4</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>0.05602</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.06888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>13.640</td>\n",
       "      <td>15.60</td>\n",
       "      <td>87.38</td>\n",
       "      <td>575.3</td>\n",
       "      <td>0.09423</td>\n",
       "      <td>0.06630</td>\n",
       "      <td>0.04705</td>\n",
       "      <td>0.037310</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.05660</td>\n",
       "      <td>...</td>\n",
       "      <td>14.85</td>\n",
       "      <td>19.05</td>\n",
       "      <td>94.11</td>\n",
       "      <td>683.4</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.15330</td>\n",
       "      <td>0.09222</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.06510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>14.060</td>\n",
       "      <td>17.18</td>\n",
       "      <td>89.75</td>\n",
       "      <td>609.1</td>\n",
       "      <td>0.08045</td>\n",
       "      <td>0.05361</td>\n",
       "      <td>0.02681</td>\n",
       "      <td>0.032510</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.05764</td>\n",
       "      <td>...</td>\n",
       "      <td>14.92</td>\n",
       "      <td>25.34</td>\n",
       "      <td>96.42</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.08460</td>\n",
       "      <td>0.07911</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>0.06609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "417       15.500         21.08          102.90      803.1          0.11200   \n",
       "36        14.250         21.72           93.63      633.0          0.09823   \n",
       "467        9.668         18.10           61.06      286.3          0.08311   \n",
       "12        19.170         24.80          132.40     1123.0          0.09740   \n",
       "267       13.590         21.84           87.16      561.0          0.07956   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "439       14.020         15.66           89.59      606.5          0.07966   \n",
       "325       12.670         17.30           81.25      489.9          0.10280   \n",
       "240       13.640         15.60           87.38      575.3          0.09423   \n",
       "395       14.060         17.18           89.75      609.1          0.08045   \n",
       "6         18.250         19.98          119.60     1040.0          0.09463   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "417           0.15710         0.15220             0.084810         0.2085   \n",
       "36            0.10980         0.13190             0.055980         0.1885   \n",
       "467           0.05428         0.01479             0.005769         0.1680   \n",
       "12            0.24580         0.20650             0.111800         0.2397   \n",
       "267           0.08259         0.04072             0.021420         0.1635   \n",
       "..                ...             ...                  ...            ...   \n",
       "439           0.05581         0.02087             0.026520         0.1589   \n",
       "325           0.07664         0.03193             0.021070         0.1707   \n",
       "240           0.06630         0.04705             0.037310         0.1717   \n",
       "395           0.05361         0.02681             0.032510         0.1641   \n",
       "6             0.10900         0.11270             0.074000         0.1794   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "417                 0.06864  ...         23.17          27.65   \n",
       "36                  0.06125  ...         15.89          30.36   \n",
       "467                 0.06412  ...         11.15          24.62   \n",
       "12                  0.07800  ...         20.96          29.94   \n",
       "267                 0.05859  ...         14.80          30.04   \n",
       "..                      ...  ...           ...            ...   \n",
       "439                 0.05586  ...         14.91          19.31   \n",
       "325                 0.05984  ...         13.71          21.10   \n",
       "240                 0.05660  ...         14.85          19.05   \n",
       "395                 0.05764  ...         14.92          25.34   \n",
       "6                   0.05742  ...         22.88          27.66   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "417           157.10      1748.0            0.1517             0.4002   \n",
       "36            116.20       799.6            0.1446             0.4238   \n",
       "467            71.11       380.2            0.1388             0.1255   \n",
       "12            151.70      1332.0            0.1037             0.3903   \n",
       "267            97.66       661.5            0.1005             0.1730   \n",
       "..               ...         ...               ...                ...   \n",
       "439            96.53       688.9            0.1034             0.1017   \n",
       "325            88.70       574.4            0.1384             0.1212   \n",
       "240            94.11       683.4            0.1278             0.1291   \n",
       "395            96.42       684.5            0.1066             0.1231   \n",
       "6             153.20      1606.0            0.1442             0.2576   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "417          0.42110               0.21340          0.3003   \n",
       "36           0.51860               0.14470          0.3591   \n",
       "467          0.06409               0.02500          0.3057   \n",
       "12           0.36390               0.17670          0.3176   \n",
       "267          0.14530               0.06189          0.2446   \n",
       "..               ...                   ...             ...   \n",
       "439          0.06260               0.08216          0.2136   \n",
       "325          0.10200               0.05602          0.2688   \n",
       "240          0.15330               0.09222          0.2530   \n",
       "395          0.08460               0.07911          0.2523   \n",
       "6            0.37840               0.19320          0.3063   \n",
       "\n",
       "     worst fractal dimension  \n",
       "417                  0.10480  \n",
       "36                   0.10140  \n",
       "467                  0.07875  \n",
       "12                   0.10230  \n",
       "267                  0.07024  \n",
       "..                       ...  \n",
       "439                  0.06710  \n",
       "325                  0.06888  \n",
       "240                  0.06510  \n",
       "395                  0.06609  \n",
       "6                    0.08368  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e645317-4915-4aba-a254-b6ad4c7b7f5f",
   "metadata": {},
   "source": [
    "##### Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe78fa5-c038-4a12-9efc-94b3fcf2fda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e461108-bf31-4416-95f8-db3138fcc0dc",
   "metadata": {},
   "source": [
    "##### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4e3350-8a66-4f85-a16e-caf2caef880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>13.21</td>\n",
       "      <td>25.25</td>\n",
       "      <td>84.10</td>\n",
       "      <td>537.9</td>\n",
       "      <td>0.08791</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.020680</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.05584</td>\n",
       "      <td>...</td>\n",
       "      <td>14.35</td>\n",
       "      <td>34.23</td>\n",
       "      <td>91.29</td>\n",
       "      <td>632.9</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.06005</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.06788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>13.05</td>\n",
       "      <td>19.31</td>\n",
       "      <td>82.61</td>\n",
       "      <td>527.2</td>\n",
       "      <td>0.08060</td>\n",
       "      <td>0.03789</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>0.05501</td>\n",
       "      <td>...</td>\n",
       "      <td>14.23</td>\n",
       "      <td>22.25</td>\n",
       "      <td>90.24</td>\n",
       "      <td>624.1</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.06191</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.01111</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>0.06289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>12.96</td>\n",
       "      <td>18.29</td>\n",
       "      <td>84.18</td>\n",
       "      <td>525.2</td>\n",
       "      <td>0.07351</td>\n",
       "      <td>0.07899</td>\n",
       "      <td>0.040570</td>\n",
       "      <td>0.018830</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>0.05899</td>\n",
       "      <td>...</td>\n",
       "      <td>14.13</td>\n",
       "      <td>24.61</td>\n",
       "      <td>96.31</td>\n",
       "      <td>621.9</td>\n",
       "      <td>0.09329</td>\n",
       "      <td>0.23180</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.06608</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.07247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>20.47</td>\n",
       "      <td>20.67</td>\n",
       "      <td>134.70</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.09156</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.05419</td>\n",
       "      <td>...</td>\n",
       "      <td>23.23</td>\n",
       "      <td>27.15</td>\n",
       "      <td>152.00</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.25340</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.16130</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>0.06386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>11.60</td>\n",
       "      <td>12.84</td>\n",
       "      <td>74.34</td>\n",
       "      <td>412.6</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.07525</td>\n",
       "      <td>0.041960</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.06582</td>\n",
       "      <td>...</td>\n",
       "      <td>13.06</td>\n",
       "      <td>17.16</td>\n",
       "      <td>82.96</td>\n",
       "      <td>512.5</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>0.18510</td>\n",
       "      <td>0.192200</td>\n",
       "      <td>0.08449</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.08756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>12.34</td>\n",
       "      <td>12.27</td>\n",
       "      <td>78.94</td>\n",
       "      <td>468.5</td>\n",
       "      <td>0.09003</td>\n",
       "      <td>0.06307</td>\n",
       "      <td>0.029580</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>0.05808</td>\n",
       "      <td>...</td>\n",
       "      <td>13.61</td>\n",
       "      <td>19.27</td>\n",
       "      <td>87.22</td>\n",
       "      <td>564.9</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.20740</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.07592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>14.97</td>\n",
       "      <td>19.76</td>\n",
       "      <td>95.50</td>\n",
       "      <td>690.2</td>\n",
       "      <td>0.08421</td>\n",
       "      <td>0.05352</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.019390</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.05266</td>\n",
       "      <td>...</td>\n",
       "      <td>15.98</td>\n",
       "      <td>25.82</td>\n",
       "      <td>102.30</td>\n",
       "      <td>782.1</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.09995</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.05754</td>\n",
       "      <td>0.2646</td>\n",
       "      <td>0.06085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>18.22</td>\n",
       "      <td>18.87</td>\n",
       "      <td>118.70</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>0.09746</td>\n",
       "      <td>0.11170</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.05664</td>\n",
       "      <td>...</td>\n",
       "      <td>21.84</td>\n",
       "      <td>25.00</td>\n",
       "      <td>140.90</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>0.14340</td>\n",
       "      <td>0.27630</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.17760</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.08198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>14.80</td>\n",
       "      <td>17.66</td>\n",
       "      <td>95.88</td>\n",
       "      <td>674.8</td>\n",
       "      <td>0.09179</td>\n",
       "      <td>0.08890</td>\n",
       "      <td>0.040690</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>0.05886</td>\n",
       "      <td>...</td>\n",
       "      <td>16.43</td>\n",
       "      <td>22.74</td>\n",
       "      <td>105.90</td>\n",
       "      <td>829.5</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.18810</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.08308</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.07285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "287        12.89         13.12           81.89      515.9          0.06955   \n",
       "457        13.21         25.25           84.10      537.9          0.08791   \n",
       "58         13.05         19.31           82.61      527.2          0.08060   \n",
       "402        12.96         18.29           84.18      525.2          0.07351   \n",
       "533        20.47         20.67          134.70     1299.0          0.09156   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "98         11.60         12.84           74.34      412.6          0.08983   \n",
       "527        12.34         12.27           78.94      468.5          0.09003   \n",
       "165        14.97         19.76           95.50      690.2          0.08421   \n",
       "317        18.22         18.87          118.70     1027.0          0.09746   \n",
       "447        14.80         17.66           95.88      674.8          0.09179   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "287           0.03729        0.022600             0.011710         0.1337   \n",
       "457           0.05205        0.027720             0.020680         0.1619   \n",
       "58            0.03789        0.000692             0.004167         0.1819   \n",
       "402           0.07899        0.040570             0.018830         0.1874   \n",
       "533           0.13130        0.152300             0.101500         0.2166   \n",
       "..                ...             ...                  ...            ...   \n",
       "98            0.07525        0.041960             0.033500         0.1620   \n",
       "527           0.06307        0.029580             0.026470         0.1689   \n",
       "165           0.05352        0.019470             0.019390         0.1515   \n",
       "317           0.11170        0.113000             0.079500         0.1807   \n",
       "447           0.08890        0.040690             0.022600         0.1893   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "287                 0.05581  ...         13.62          15.54   \n",
       "457                 0.05584  ...         14.35          34.23   \n",
       "58                  0.05501  ...         14.23          22.25   \n",
       "402                 0.05899  ...         14.13          24.61   \n",
       "533                 0.05419  ...         23.23          27.15   \n",
       "..                      ...  ...           ...            ...   \n",
       "98                  0.06582  ...         13.06          17.16   \n",
       "527                 0.05808  ...         13.61          19.27   \n",
       "165                 0.05266  ...         15.98          25.82   \n",
       "317                 0.05664  ...         21.84          25.00   \n",
       "447                 0.05886  ...         16.43          22.74   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "287            87.40       577.0           0.09616            0.11470   \n",
       "457            91.29       632.9           0.12890            0.10630   \n",
       "58             90.24       624.1           0.10210            0.06191   \n",
       "402            96.31       621.9           0.09329            0.23180   \n",
       "533           152.00      1645.0           0.10970            0.25340   \n",
       "..               ...         ...               ...                ...   \n",
       "98             82.96       512.5           0.14310            0.18510   \n",
       "527            87.22       564.9           0.12920            0.20740   \n",
       "165           102.30       782.1           0.10450            0.09995   \n",
       "317           140.90      1485.0           0.14340            0.27630   \n",
       "447           105.90       829.5           0.12260            0.18810   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "287         0.118600               0.05366          0.2309   \n",
       "457         0.139000               0.06005          0.2444   \n",
       "58          0.001845               0.01111          0.2439   \n",
       "402         0.160400               0.06608          0.3207   \n",
       "533         0.309200               0.16130          0.3220   \n",
       "..               ...                   ...             ...   \n",
       "98          0.192200               0.08449          0.2772   \n",
       "527         0.179100               0.10700          0.3110   \n",
       "165         0.077500               0.05754          0.2646   \n",
       "317         0.385300               0.17760          0.2812   \n",
       "447         0.206000               0.08308          0.3600   \n",
       "\n",
       "     worst fractal dimension  \n",
       "287                  0.06915  \n",
       "457                  0.06788  \n",
       "58                   0.06289  \n",
       "402                  0.07247  \n",
       "533                  0.06386  \n",
       "..                       ...  \n",
       "98                   0.08756  \n",
       "527                  0.07592  \n",
       "165                  0.06085  \n",
       "317                  0.08198  \n",
       "447                  0.07285  \n",
       "\n",
       "[114 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b3d02-5c59-40e3-bf35-0610b18bcde0",
   "metadata": {},
   "source": [
    "##### Testing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a696a349-9b4a-4712-acb1-f076134618e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c683d0-122f-436b-8cea-9b7ee860db97",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf951515-865e-4aba-a985-9cd419533cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(train_data)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d69182-8e05-41e1-974f-1317e3dcae00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.95371296e+01, 2.16480556e+01, 1.29350000e+02, 1.20440556e+03,\n",
       "        1.01297407e-01, 1.49663981e-01, 1.79123056e-01, 1.02168889e-01,\n",
       "        1.92343519e-01, 6.05057407e-02, 7.59812037e-01, 1.22479907e+00,\n",
       "        5.41451852e+00, 9.87950000e+01, 6.64048148e-03, 3.29706759e-02,\n",
       "        4.33628704e-02, 1.60463611e-02, 2.09387037e-02, 4.04947222e-03,\n",
       "        2.38387963e+01, 2.86327778e+01, 1.59831481e+02, 1.76930556e+03,\n",
       "        1.39364074e-01, 3.56578704e-01, 4.46473148e-01, 1.93628796e-01,\n",
       "        3.12497222e-01, 8.57380556e-02],\n",
       "       [1.25613718e+01, 1.85079827e+01, 8.11861383e+01, 4.96297118e+02,\n",
       "        9.52937464e-02, 9.15554179e-02, 6.37102758e-02, 3.38157925e-02,\n",
       "        1.78862536e-01, 6.35052450e-02, 3.05165706e-01, 1.21916138e+00,\n",
       "        2.15748386e+00, 2.39151873e+01, 7.17349280e-03, 2.37632478e-02,\n",
       "        2.92912438e-02, 1.07994957e-02, 2.07424150e-02, 3.80456571e-03,\n",
       "        1.40474496e+01, 2.46396830e+01, 9.20183285e+01, 6.20159654e+02,\n",
       "        1.30449020e-01, 2.26534063e-01, 2.25104876e-01, 9.25440663e-02,\n",
       "        2.84997118e-01, 8.35015850e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1b5d22-e787-47e3-9cb8-dbae41c09b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25 11]\n",
      " [ 1 77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction = kmeans.fit_predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c551f37-6797-4d8d-8e7e-ccc7d552e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.81        36\n",
      "           1       0.88      0.99      0.93        78\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.84      0.87       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1901300a-cecb-4c12-ad25-0b5fb94b86a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.8947368421052632\n",
      "Precision    : 0.875\n",
      "Recall       : 0.9871794871794872\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbce2ec-447f-4670-a87b-432ffb635925",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c37e62-992b-4278-8378-e9d99eef1d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ddf801-6f9a-46cf-9d91-a685443230e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  1]\n",
      " [ 1 77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction=logreg.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fecc397b-1300-4489-9e2a-1db453908ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        36\n",
      "           1       0.99      0.99      0.99        78\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e230e7-1e88-43ce-96bb-b15bb0da15fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9824561403508771\n",
      "Precision    : 0.9871794871794872\n",
      "Recall       : 0.9871794871794872\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc299600-a729-4981-ab38-a9d4fcc27911",
   "metadata": {},
   "source": [
    "#### Neural Network MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da354644-d8cd-4189-8343-bdb63b25d7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hughie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=300, random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpc = MLPClassifier(random_state=1, max_iter=300, solver='lbfgs')\n",
    "mlpc.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb1ed855-b450-4de4-85cc-0c1e98917e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  1]\n",
      " [ 1 77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction=logreg.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64da07e7-1e5d-4a08-8d7b-58626ebf85cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        36\n",
      "           1       0.99      0.99      0.99        78\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d469e18e-6fb1-462a-bf31-66b820ab7c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9824561403508771\n",
      "Precision    : 0.9871794871794872\n",
      "Recall       : 0.9871794871794872\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
