{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca90635-0662-4d2e-91e3-7dd4117ab803",
   "metadata": {},
   "source": [
    "# Tugas Kecil 1 IF3270 Pembelajaran Mesin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b109e0f-1017-48e0-80fc-c79c61ef02c9",
   "metadata": {},
   "source": [
    "### Anggota Kelompok\n",
    "### - 13519057 Kadek Dwi Bagus\n",
    "### - 13519217 Hughie Alghaniyyu Emiliano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b0ca6-7dcb-4d3c-9c6d-069b570354b4",
   "metadata": {},
   "source": [
    "#### Import Dataset Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9c787477-08c8-4a2e-8e50-a34076910b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension    Species  \n",
       "0                  0.2654          0.4601                  0.11890  malignant  \n",
       "1                  0.1860          0.2750                  0.08902  malignant  \n",
       "2                  0.2430          0.3613                  0.08758  malignant  \n",
       "3                  0.2575          0.6638                  0.17300  malignant  \n",
       "4                  0.1625          0.2364                  0.07678  malignant  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115  malignant  \n",
       "565                0.1628          0.2572                  0.06637  malignant  \n",
       "566                0.1418          0.2218                  0.07820  malignant  \n",
       "567                0.2650          0.4087                  0.12400  malignant  \n",
       "568                0.0000          0.2871                  0.07039     benign  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "df = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names).assign(Species=breast_cancer_data['target_names'][breast_cancer_data.target])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cda95-7afc-4dc9-8ea9-34c88a9f8202",
   "metadata": {},
   "source": [
    "#### Split Dataset to 80% for Training and 20% for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3a3aee46-69a7-46df-9998-1b2fc10141ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of training data : 455 (79.96%)\n",
      "Amount of testing data  : 114 (20.04%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names)\n",
    "result = breast_cancer_data.target\n",
    "train_data, test_data, train_result, test_result = train_test_split(data, result, test_size=0.20)\n",
    "\n",
    "train_percentage = round((train_data.shape[0] / (train_data.shape[0] + test_data.shape[0])) * 100, 2)\n",
    "print(f\"Amount of training data : {train_data.shape[0]} ({train_percentage}%)\")\n",
    "\n",
    "test_percentage = round((test_data.shape[0] / (train_data.shape[0] + test_data.shape[0])) * 100, 2)\n",
    "print(f\"Amount of testing data  : {test_data.shape[0]} ({test_percentage}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd4e22-5e49-40fa-924a-46c0e71ec100",
   "metadata": {},
   "source": [
    "##### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b61e6e14-c70b-42c4-a32d-38ecbd949572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>10.48</td>\n",
       "      <td>19.86</td>\n",
       "      <td>66.72</td>\n",
       "      <td>337.7</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.05971</td>\n",
       "      <td>0.04831</td>\n",
       "      <td>0.03070</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.06440</td>\n",
       "      <td>...</td>\n",
       "      <td>11.48</td>\n",
       "      <td>29.46</td>\n",
       "      <td>73.68</td>\n",
       "      <td>402.8</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.06736</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.07748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>12.00</td>\n",
       "      <td>28.23</td>\n",
       "      <td>76.77</td>\n",
       "      <td>442.5</td>\n",
       "      <td>0.08437</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>0.04055</td>\n",
       "      <td>0.01945</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.06104</td>\n",
       "      <td>...</td>\n",
       "      <td>13.09</td>\n",
       "      <td>37.88</td>\n",
       "      <td>85.07</td>\n",
       "      <td>523.7</td>\n",
       "      <td>0.12080</td>\n",
       "      <td>0.18560</td>\n",
       "      <td>0.18110</td>\n",
       "      <td>0.07116</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.08194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>10.91</td>\n",
       "      <td>12.35</td>\n",
       "      <td>69.14</td>\n",
       "      <td>363.7</td>\n",
       "      <td>0.08518</td>\n",
       "      <td>0.04721</td>\n",
       "      <td>0.01236</td>\n",
       "      <td>0.01369</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.06031</td>\n",
       "      <td>...</td>\n",
       "      <td>11.37</td>\n",
       "      <td>14.82</td>\n",
       "      <td>72.42</td>\n",
       "      <td>392.2</td>\n",
       "      <td>0.09312</td>\n",
       "      <td>0.07506</td>\n",
       "      <td>0.02884</td>\n",
       "      <td>0.03194</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.06643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>14.86</td>\n",
       "      <td>16.94</td>\n",
       "      <td>94.89</td>\n",
       "      <td>673.7</td>\n",
       "      <td>0.08924</td>\n",
       "      <td>0.07074</td>\n",
       "      <td>0.03346</td>\n",
       "      <td>0.02877</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.05703</td>\n",
       "      <td>...</td>\n",
       "      <td>16.31</td>\n",
       "      <td>20.54</td>\n",
       "      <td>102.30</td>\n",
       "      <td>777.5</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.15500</td>\n",
       "      <td>0.12200</td>\n",
       "      <td>0.07971</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>0.06827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14.86</td>\n",
       "      <td>23.21</td>\n",
       "      <td>100.40</td>\n",
       "      <td>671.4</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.08878</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.06672</td>\n",
       "      <td>...</td>\n",
       "      <td>16.08</td>\n",
       "      <td>27.78</td>\n",
       "      <td>118.60</td>\n",
       "      <td>784.7</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.46480</td>\n",
       "      <td>0.45890</td>\n",
       "      <td>0.17270</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.08701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>12.00</td>\n",
       "      <td>15.65</td>\n",
       "      <td>76.95</td>\n",
       "      <td>443.3</td>\n",
       "      <td>0.09723</td>\n",
       "      <td>0.07165</td>\n",
       "      <td>0.04151</td>\n",
       "      <td>0.01863</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>0.05968</td>\n",
       "      <td>...</td>\n",
       "      <td>13.67</td>\n",
       "      <td>24.90</td>\n",
       "      <td>87.78</td>\n",
       "      <td>567.9</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.20030</td>\n",
       "      <td>0.22670</td>\n",
       "      <td>0.07632</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.07924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>13.27</td>\n",
       "      <td>17.02</td>\n",
       "      <td>84.55</td>\n",
       "      <td>546.4</td>\n",
       "      <td>0.08445</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.03554</td>\n",
       "      <td>0.02456</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.05674</td>\n",
       "      <td>...</td>\n",
       "      <td>15.14</td>\n",
       "      <td>23.60</td>\n",
       "      <td>98.84</td>\n",
       "      <td>708.8</td>\n",
       "      <td>0.12760</td>\n",
       "      <td>0.13110</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.09678</td>\n",
       "      <td>0.2506</td>\n",
       "      <td>0.07623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>10.51</td>\n",
       "      <td>20.19</td>\n",
       "      <td>68.64</td>\n",
       "      <td>334.2</td>\n",
       "      <td>0.11220</td>\n",
       "      <td>0.13030</td>\n",
       "      <td>0.06476</td>\n",
       "      <td>0.03068</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.07782</td>\n",
       "      <td>...</td>\n",
       "      <td>11.16</td>\n",
       "      <td>22.75</td>\n",
       "      <td>72.62</td>\n",
       "      <td>374.4</td>\n",
       "      <td>0.13000</td>\n",
       "      <td>0.20490</td>\n",
       "      <td>0.12950</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>0.09026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>12.27</td>\n",
       "      <td>17.92</td>\n",
       "      <td>78.41</td>\n",
       "      <td>466.1</td>\n",
       "      <td>0.08685</td>\n",
       "      <td>0.06526</td>\n",
       "      <td>0.03211</td>\n",
       "      <td>0.02653</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.05597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.10</td>\n",
       "      <td>28.88</td>\n",
       "      <td>89.00</td>\n",
       "      <td>610.2</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.17950</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.09532</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.06896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>12.72</td>\n",
       "      <td>17.67</td>\n",
       "      <td>80.98</td>\n",
       "      <td>501.3</td>\n",
       "      <td>0.07896</td>\n",
       "      <td>0.04522</td>\n",
       "      <td>0.01402</td>\n",
       "      <td>0.01835</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>20.96</td>\n",
       "      <td>88.87</td>\n",
       "      <td>586.8</td>\n",
       "      <td>0.10680</td>\n",
       "      <td>0.09605</td>\n",
       "      <td>0.03469</td>\n",
       "      <td>0.03612</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.06025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "245        10.48         19.86           66.72      337.7          0.10700   \n",
       "452        12.00         28.23           76.77      442.5          0.08437   \n",
       "296        10.91         12.35           69.14      363.7          0.08518   \n",
       "434        14.86         16.94           94.89      673.7          0.08924   \n",
       "194        14.86         23.21          100.40      671.4          0.10440   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "84         12.00         15.65           76.95      443.3          0.09723   \n",
       "224        13.27         17.02           84.55      546.4          0.08445   \n",
       "113        10.51         20.19           68.64      334.2          0.11220   \n",
       "409        12.27         17.92           78.41      466.1          0.08685   \n",
       "429        12.72         17.67           80.98      501.3          0.07896   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "245           0.05971         0.04831              0.03070         0.1737   \n",
       "452           0.06450         0.04055              0.01945         0.1615   \n",
       "296           0.04721         0.01236              0.01369         0.1449   \n",
       "434           0.07074         0.03346              0.02877         0.1573   \n",
       "194           0.19800         0.16970              0.08878         0.1737   \n",
       "..                ...             ...                  ...            ...   \n",
       "84            0.07165         0.04151              0.01863         0.2079   \n",
       "224           0.04994         0.03554              0.02456         0.1496   \n",
       "113           0.13030         0.06476              0.03068         0.1922   \n",
       "409           0.06526         0.03211              0.02653         0.1966   \n",
       "429           0.04522         0.01402              0.01835         0.1459   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "245                 0.06440  ...         11.48          29.46   \n",
       "452                 0.06104  ...         13.09          37.88   \n",
       "296                 0.06031  ...         11.37          14.82   \n",
       "434                 0.05703  ...         16.31          20.54   \n",
       "194                 0.06672  ...         16.08          27.78   \n",
       "..                      ...  ...           ...            ...   \n",
       "84                  0.05968  ...         13.67          24.90   \n",
       "224                 0.05674  ...         15.14          23.60   \n",
       "113                 0.07782  ...         11.16          22.75   \n",
       "409                 0.05597  ...         14.10          28.88   \n",
       "429                 0.05544  ...         13.82          20.96   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "245            73.68       402.8           0.15150            0.10260   \n",
       "452            85.07       523.7           0.12080            0.18560   \n",
       "296            72.42       392.2           0.09312            0.07506   \n",
       "434           102.30       777.5           0.12180            0.15500   \n",
       "194           118.60       784.7           0.13160            0.46480   \n",
       "..               ...         ...               ...                ...   \n",
       "84             87.78       567.9           0.13770            0.20030   \n",
       "224            98.84       708.8           0.12760            0.13110   \n",
       "113            72.62       374.4           0.13000            0.20490   \n",
       "409            89.00       610.2           0.12400            0.17950   \n",
       "429            88.87       586.8           0.10680            0.09605   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "245          0.11810               0.06736          0.2883   \n",
       "452          0.18110               0.07116          0.2447   \n",
       "296          0.02884               0.03194          0.2143   \n",
       "434          0.12200               0.07971          0.2525   \n",
       "194          0.45890               0.17270          0.3000   \n",
       "..               ...                   ...             ...   \n",
       "84           0.22670               0.07632          0.3379   \n",
       "224          0.17860               0.09678          0.2506   \n",
       "113          0.12950               0.06136          0.2383   \n",
       "409          0.13770               0.09532          0.3455   \n",
       "429          0.03469               0.03612          0.2165   \n",
       "\n",
       "     worst fractal dimension  \n",
       "245                  0.07748  \n",
       "452                  0.08194  \n",
       "296                  0.06643  \n",
       "434                  0.06827  \n",
       "194                  0.08701  \n",
       "..                       ...  \n",
       "84                   0.07924  \n",
       "224                  0.07623  \n",
       "113                  0.09026  \n",
       "409                  0.06896  \n",
       "429                  0.06025  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e645317-4915-4aba-a254-b6ad4c7b7f5f",
   "metadata": {},
   "source": [
    "##### Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ffe78fa5-c038-4a12-9efc-94b3fcf2fda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e461108-bf31-4416-95f8-db3138fcc0dc",
   "metadata": {},
   "source": [
    "##### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "df4e3350-8a66-4f85-a16e-caf2caef880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>13.86</td>\n",
       "      <td>16.93</td>\n",
       "      <td>90.96</td>\n",
       "      <td>578.9</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>0.056020</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.06916</td>\n",
       "      <td>...</td>\n",
       "      <td>15.75</td>\n",
       "      <td>26.93</td>\n",
       "      <td>104.40</td>\n",
       "      <td>750.1</td>\n",
       "      <td>0.14600</td>\n",
       "      <td>0.43700</td>\n",
       "      <td>0.46360</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.10590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>11.62</td>\n",
       "      <td>18.18</td>\n",
       "      <td>76.38</td>\n",
       "      <td>408.8</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.14830</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.07255</td>\n",
       "      <td>...</td>\n",
       "      <td>13.36</td>\n",
       "      <td>25.40</td>\n",
       "      <td>88.14</td>\n",
       "      <td>528.1</td>\n",
       "      <td>0.17800</td>\n",
       "      <td>0.28780</td>\n",
       "      <td>0.31860</td>\n",
       "      <td>0.14160</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.09270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>11.06</td>\n",
       "      <td>14.83</td>\n",
       "      <td>70.31</td>\n",
       "      <td>378.2</td>\n",
       "      <td>0.07741</td>\n",
       "      <td>0.04768</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.06214</td>\n",
       "      <td>...</td>\n",
       "      <td>12.68</td>\n",
       "      <td>20.35</td>\n",
       "      <td>80.79</td>\n",
       "      <td>496.7</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.18790</td>\n",
       "      <td>0.20790</td>\n",
       "      <td>0.05556</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>0.09158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10.17</td>\n",
       "      <td>14.88</td>\n",
       "      <td>64.55</td>\n",
       "      <td>311.9</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>0.08061</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.06960</td>\n",
       "      <td>...</td>\n",
       "      <td>11.02</td>\n",
       "      <td>17.45</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.6</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>13.50</td>\n",
       "      <td>12.71</td>\n",
       "      <td>85.69</td>\n",
       "      <td>566.2</td>\n",
       "      <td>0.07376</td>\n",
       "      <td>0.03614</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.05335</td>\n",
       "      <td>...</td>\n",
       "      <td>14.97</td>\n",
       "      <td>16.94</td>\n",
       "      <td>95.48</td>\n",
       "      <td>698.7</td>\n",
       "      <td>0.09023</td>\n",
       "      <td>0.05836</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.02210</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.06192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>11.80</td>\n",
       "      <td>16.58</td>\n",
       "      <td>78.99</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0.10910</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.074150</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.07371</td>\n",
       "      <td>...</td>\n",
       "      <td>13.74</td>\n",
       "      <td>26.38</td>\n",
       "      <td>91.93</td>\n",
       "      <td>591.7</td>\n",
       "      <td>0.13850</td>\n",
       "      <td>0.40920</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.18650</td>\n",
       "      <td>0.5774</td>\n",
       "      <td>0.10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>15.32</td>\n",
       "      <td>17.27</td>\n",
       "      <td>103.20</td>\n",
       "      <td>713.3</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.22840</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.07596</td>\n",
       "      <td>...</td>\n",
       "      <td>17.73</td>\n",
       "      <td>22.66</td>\n",
       "      <td>119.80</td>\n",
       "      <td>928.8</td>\n",
       "      <td>0.17650</td>\n",
       "      <td>0.45030</td>\n",
       "      <td>0.44290</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.11910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.08</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.95</td>\n",
       "      <td>21.35</td>\n",
       "      <td>71.90</td>\n",
       "      <td>371.1</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.056690</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.06870</td>\n",
       "      <td>...</td>\n",
       "      <td>12.84</td>\n",
       "      <td>35.34</td>\n",
       "      <td>87.22</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.19090</td>\n",
       "      <td>0.26980</td>\n",
       "      <td>0.40230</td>\n",
       "      <td>0.14240</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.09606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10.75</td>\n",
       "      <td>14.97</td>\n",
       "      <td>68.26</td>\n",
       "      <td>355.3</td>\n",
       "      <td>0.07793</td>\n",
       "      <td>0.05139</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>...</td>\n",
       "      <td>11.95</td>\n",
       "      <td>20.72</td>\n",
       "      <td>77.79</td>\n",
       "      <td>441.2</td>\n",
       "      <td>0.10760</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.09755</td>\n",
       "      <td>0.03413</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.06769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "215        13.86         16.93           90.96      578.9          0.10260   \n",
       "469        11.62         18.18           76.38      408.8          0.11750   \n",
       "398        11.06         14.83           70.31      378.2          0.07741   \n",
       "60         10.17         14.88           64.55      311.9          0.11340   \n",
       "308        13.50         12.71           85.69      566.2          0.07376   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "146        11.80         16.58           78.99      432.0          0.10910   \n",
       "257        15.32         17.27          103.20      713.3          0.13350   \n",
       "20         13.08         15.71           85.63      520.0          0.10750   \n",
       "41         10.95         21.35           71.90      371.1          0.12270   \n",
       "144        10.75         14.97           68.26      355.3          0.07793   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "215           0.15170        0.099010             0.056020         0.2106   \n",
       "469           0.14830        0.102000             0.055640         0.1957   \n",
       "398           0.04768        0.027120             0.007246         0.1535   \n",
       "60            0.08061        0.010840             0.012900         0.2743   \n",
       "308           0.03614        0.002758             0.004419         0.1365   \n",
       "..                ...             ...                  ...            ...   \n",
       "146           0.17000        0.165900             0.074150         0.2678   \n",
       "257           0.22840        0.244800             0.124200         0.2398   \n",
       "20            0.12700        0.045680             0.031100         0.1967   \n",
       "41            0.12180        0.104400             0.056690         0.1895   \n",
       "144           0.05139        0.022510             0.007875         0.1399   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "215                 0.06916  ...         15.75          26.93   \n",
       "469                 0.07255  ...         13.36          25.40   \n",
       "398                 0.06214  ...         12.68          20.35   \n",
       "60                  0.06960  ...         11.02          17.45   \n",
       "308                 0.05335  ...         14.97          16.94   \n",
       "..                      ...  ...           ...            ...   \n",
       "146                 0.07371  ...         13.74          26.38   \n",
       "257                 0.07596  ...         17.73          22.66   \n",
       "20                  0.06811  ...         14.50          20.49   \n",
       "41                  0.06870  ...         12.84          35.34   \n",
       "144                 0.05688  ...         11.95          20.72   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "215           104.40       750.1           0.14600            0.43700   \n",
       "469            88.14       528.1           0.17800            0.28780   \n",
       "398            80.79       496.7           0.11200            0.18790   \n",
       "60             69.86       368.6           0.12750            0.09866   \n",
       "308            95.48       698.7           0.09023            0.05836   \n",
       "..               ...         ...               ...                ...   \n",
       "146            91.93       591.7           0.13850            0.40920   \n",
       "257           119.80       928.8           0.17650            0.45030   \n",
       "20             96.09       630.5           0.13120            0.27760   \n",
       "41             87.22       514.0           0.19090            0.26980   \n",
       "144            77.79       441.2           0.10760            0.12230   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "215          0.46360               0.16540          0.3630   \n",
       "469          0.31860               0.14160          0.2660   \n",
       "398          0.20790               0.05556          0.2590   \n",
       "60           0.02168               0.02579          0.3557   \n",
       "308          0.01379               0.02210          0.2267   \n",
       "..               ...                   ...             ...   \n",
       "146          0.45040               0.18650          0.5774   \n",
       "257          0.44290               0.22290          0.3258   \n",
       "20           0.18900               0.07283          0.3184   \n",
       "41           0.40230               0.14240          0.2964   \n",
       "144          0.09755               0.03413          0.2300   \n",
       "\n",
       "     worst fractal dimension  \n",
       "215                  0.10590  \n",
       "469                  0.09270  \n",
       "398                  0.09158  \n",
       "60                   0.08020  \n",
       "308                  0.06192  \n",
       "..                       ...  \n",
       "146                  0.10300  \n",
       "257                  0.11910  \n",
       "20                   0.08183  \n",
       "41                   0.09606  \n",
       "144                  0.06769  \n",
       "\n",
       "[114 rows x 30 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b3d02-5c59-40e3-bf35-0610b18bcde0",
   "metadata": {},
   "source": [
    "##### Testing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a696a349-9b4a-4712-acb1-f076134618e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3d750",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c9039a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.7102272727272727, 0.9375, 'X[23] <= 865.65\\ngini = 0.463\\nsamples = 455\\nvalue = [166, 289]'),\n",
       " Text(0.5113636363636364, 0.8125, 'X[27] <= 0.16\\ngini = 0.159\\nsamples = 309\\nvalue = [27, 282]'),\n",
       " Text(0.3409090909090909, 0.6875, 'X[27] <= 0.132\\ngini = 0.079\\nsamples = 292\\nvalue = [12, 280]'),\n",
       " Text(0.22727272727272727, 0.5625, 'X[10] <= 1.048\\ngini = 0.022\\nsamples = 265\\nvalue = [3, 262]'),\n",
       " Text(0.18181818181818182, 0.4375, 'X[14] <= 0.003\\ngini = 0.015\\nsamples = 264\\nvalue = [2, 262]'),\n",
       " Text(0.09090909090909091, 0.3125, 'X[1] <= 19.875\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(0.045454545454545456, 0.1875, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(0.13636363636363635, 0.1875, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.2727272727272727, 0.3125, 'X[21] <= 33.35\\ngini = 0.008\\nsamples = 258\\nvalue = [1, 257]'),\n",
       " Text(0.22727272727272727, 0.1875, 'gini = 0.0\\nsamples = 243\\nvalue = [0, 243]'),\n",
       " Text(0.3181818181818182, 0.1875, 'X[1] <= 23.2\\ngini = 0.124\\nsamples = 15\\nvalue = [1, 14]'),\n",
       " Text(0.2727272727272727, 0.0625, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.36363636363636365, 0.0625, 'gini = 0.0\\nsamples = 14\\nvalue = [0, 14]'),\n",
       " Text(0.2727272727272727, 0.4375, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.45454545454545453, 0.5625, 'X[21] <= 28.81\\ngini = 0.444\\nsamples = 27\\nvalue = [9, 18]'),\n",
       " Text(0.4090909090909091, 0.4375, 'X[29] <= 0.073\\ngini = 0.18\\nsamples = 20\\nvalue = [2, 18]'),\n",
       " Text(0.36363636363636365, 0.3125, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.45454545454545453, 0.3125, 'X[4] <= 0.109\\ngini = 0.1\\nsamples = 19\\nvalue = [1, 18]'),\n",
       " Text(0.4090909090909091, 0.1875, 'gini = 0.0\\nsamples = 16\\nvalue = [0, 16]'),\n",
       " Text(0.5, 0.1875, 'X[18] <= 0.022\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(0.45454545454545453, 0.0625, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.5454545454545454, 0.0625, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(0.5, 0.4375, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(0.6818181818181818, 0.6875, 'X[21] <= 23.47\\ngini = 0.208\\nsamples = 17\\nvalue = [15, 2]'),\n",
       " Text(0.6363636363636364, 0.5625, 'X[29] <= 0.129\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(0.5909090909090909, 0.4375, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(0.6818181818181818, 0.4375, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.7272727272727273, 0.5625, 'gini = 0.0\\nsamples = 14\\nvalue = [14, 0]'),\n",
       " Text(0.9090909090909091, 0.8125, 'X[6] <= 0.072\\ngini = 0.091\\nsamples = 146\\nvalue = [139, 7]'),\n",
       " Text(0.8636363636363636, 0.6875, 'X[1] <= 19.545\\ngini = 0.484\\nsamples = 17\\nvalue = [10, 7]'),\n",
       " Text(0.8181818181818182, 0.5625, 'X[17] <= 0.006\\ngini = 0.219\\nsamples = 8\\nvalue = [1, 7]'),\n",
       " Text(0.7727272727272727, 0.4375, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.8636363636363636, 0.4375, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
       " Text(0.9090909090909091, 0.5625, 'gini = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(0.9545454545454546, 0.6875, 'gini = 0.0\\nsamples = 129\\nvalue = [129, 0]')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clfDTC = tree.DecisionTreeClassifier()\n",
    "clfDTC = clfDTC.fit(train_data, train_result)\n",
    "tree.plot_tree(clfDTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0344296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  3]\n",
      " [ 3 65]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction = clfDTC.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "78b90998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        46\n",
      "           1       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.95      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4f3a6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9473684210526315\n",
      "Precision    : 0.9558823529411765\n",
      "Recall       : 0.9558823529411765\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c683d0-122f-436b-8cea-9b7ee860db97",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf951515-865e-4aba-a985-9cd419533cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(train_data)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d0d69182-8e05-41e1-974f-1317e3dcae00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.25924282e+01, 1.87094930e+01, 8.13897746e+01, 4.99349014e+02,\n",
       "        9.48042817e-02, 9.20466479e-02, 6.40088949e-02, 3.36619380e-02,\n",
       "        1.77628451e-01, 6.35065634e-02, 3.06206761e-01, 1.21301465e+00,\n",
       "        2.17381606e+00, 2.41117915e+01, 7.25612113e-03, 2.41627408e-02,\n",
       "        2.99329313e-02, 1.07530817e-02, 2.03854113e-02, 3.87132423e-03,\n",
       "        1.40747803e+01, 2.47826479e+01, 9.21992113e+01, 6.23349296e+02,\n",
       "        1.29732901e-01, 2.25144254e-01, 2.24154231e-01, 9.15348197e-02,\n",
       "        2.81512394e-01, 8.34420845e-02],\n",
       "       [1.95028000e+01, 2.17498000e+01, 1.29040000e+02, 1.20280200e+03,\n",
       "        1.00328100e-01, 1.45636700e-01, 1.75434000e-01, 9.98507000e-02,\n",
       "        1.89972000e-01, 6.03606000e-02, 7.47133000e-01, 1.22100700e+00,\n",
       "        5.29996000e+00, 9.69778000e+01, 6.60065000e-03, 3.18073700e-02,\n",
       "        4.24732000e-02, 1.55936700e-02, 2.08053000e-02, 3.95038000e-03,\n",
       "        2.36601000e+01, 2.87737000e+01, 1.58298000e+02, 1.74988000e+03,\n",
       "        1.37998400e-01, 3.48645600e-01, 4.40061000e-01, 1.89516700e-01,\n",
       "        3.09260000e-01, 8.50051000e-02]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "da1b5d22-e787-47e3-9cb8-dbae41c09b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16 30]\n",
      " [68  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction = kmeans.fit_predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9c551f37-6797-4d8d-8e7e-ccc7d552e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.35      0.25        46\n",
      "           1       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.14       114\n",
      "   macro avg       0.10      0.17      0.12       114\n",
      "weighted avg       0.08      0.14      0.10       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1901300a-cecb-4c12-ad25-0b5fb94b86a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.14035087719298245\n",
      "Precision    : 0.0\n",
      "Recall       : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbce2ec-447f-4670-a87b-432ffb635925",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "45c37e62-992b-4278-8378-e9d99eef1d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "47ddf801-6f9a-46cf-9d91-a685443230e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  6]\n",
      " [ 2 66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction=logreg.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fecc397b-1300-4489-9e2a-1db453908ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91        46\n",
      "           1       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "25e230e7-1e88-43ce-96bb-b15bb0da15fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9298245614035088\n",
      "Precision    : 0.9166666666666666\n",
      "Recall       : 0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc299600-a729-4981-ab38-a9d4fcc27911",
   "metadata": {},
   "source": [
    "#### Neural Network MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "da354644-d8cd-4189-8343-bdb63b25d7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=300, random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpc = MLPClassifier(random_state=1, max_iter=300, solver='lbfgs')\n",
    "mlpc.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eb1ed855-b450-4de4-85cc-0c1e98917e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  6]\n",
      " [ 2 66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction=logreg.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "64da07e7-1e5d-4a08-8d7b-58626ebf85cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91        46\n",
      "           1       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d469e18e-6fb1-462a-bf31-66b820ab7c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9298245614035088\n",
      "Precision    : 0.9166666666666666\n",
      "Recall       : 0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f99bc0",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6fe58d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "\n",
    "clfSVM = svm.SVC()\n",
    "clfSVM.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "51ae82e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  8]\n",
      " [ 1 67]]\n"
     ]
    }
   ],
   "source": [
    "prediction = clfSVM.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3ee312d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.89        46\n",
      "           1       0.89      0.99      0.94        68\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "834384b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9210526315789473\n",
      "Precision    : 0.8933333333333333\n",
      "Recall       : 0.9852941176470589\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
