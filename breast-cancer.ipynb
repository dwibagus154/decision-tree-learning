{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca90635-0662-4d2e-91e3-7dd4117ab803",
   "metadata": {},
   "source": [
    "# Tugas Kecil 1 IF3270 Pembelajaran Mesin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b109e0f-1017-48e0-80fc-c79c61ef02c9",
   "metadata": {},
   "source": [
    "### Anggota Kelompok\n",
    "### - 13519057 Kadek Dwi Bagus\n",
    "### - 13519217 Hughie Alghaniyyu Emiliano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b0ca6-7dcb-4d3c-9c6d-069b570354b4",
   "metadata": {},
   "source": [
    "#### Import Dataset Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c787477-08c8-4a2e-8e50-a34076910b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension    Species  \n",
       "0                  0.2654          0.4601                  0.11890  malignant  \n",
       "1                  0.1860          0.2750                  0.08902  malignant  \n",
       "2                  0.2430          0.3613                  0.08758  malignant  \n",
       "3                  0.2575          0.6638                  0.17300  malignant  \n",
       "4                  0.1625          0.2364                  0.07678  malignant  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115  malignant  \n",
       "565                0.1628          0.2572                  0.06637  malignant  \n",
       "566                0.1418          0.2218                  0.07820  malignant  \n",
       "567                0.2650          0.4087                  0.12400  malignant  \n",
       "568                0.0000          0.2871                  0.07039     benign  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "df = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names).assign(Species=breast_cancer_data['target_names'][breast_cancer_data.target])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cda95-7afc-4dc9-8ea9-34c88a9f8202",
   "metadata": {},
   "source": [
    "#### Split Dataset to 80% for Training and 20% for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a3aee46-69a7-46df-9998-1b2fc10141ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of training data : 455 (79.96%)\n",
      "Amount of testing data  : 114 (20.04%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.DataFrame(breast_cancer_data.data, columns=breast_cancer_data.feature_names)\n",
    "result = breast_cancer_data.target\n",
    "train_data, test_data, train_result, test_result = train_test_split(data, result, test_size=0.20)\n",
    "\n",
    "train_percentage = round((train_data.shape[0] / (train_data.shape[0] + test_data.shape[0])) * 100, 2)\n",
    "print(f\"Amount of training data : {train_data.shape[0]} ({train_percentage}%)\")\n",
    "\n",
    "test_percentage = round((test_data.shape[0] / (train_data.shape[0] + test_data.shape[0])) * 100, 2)\n",
    "print(f\"Amount of testing data  : {test_data.shape[0]} ({test_percentage}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd4e22-5e49-40fa-924a-46c0e71ec100",
   "metadata": {},
   "source": [
    "##### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b61e6e14-c70b-42c4-a32d-38ecbd949572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>10.08</td>\n",
       "      <td>15.11</td>\n",
       "      <td>63.76</td>\n",
       "      <td>317.5</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.04695</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.06048</td>\n",
       "      <td>...</td>\n",
       "      <td>11.87</td>\n",
       "      <td>21.18</td>\n",
       "      <td>75.39</td>\n",
       "      <td>437.0</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.00692</td>\n",
       "      <td>0.01042</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.07697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>14.22</td>\n",
       "      <td>23.12</td>\n",
       "      <td>94.37</td>\n",
       "      <td>609.9</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.24130</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.066180</td>\n",
       "      <td>0.2384</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>...</td>\n",
       "      <td>15.74</td>\n",
       "      <td>37.18</td>\n",
       "      <td>106.40</td>\n",
       "      <td>762.4</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.84880</td>\n",
       "      <td>0.17720</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.14460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>14.27</td>\n",
       "      <td>22.55</td>\n",
       "      <td>93.77</td>\n",
       "      <td>629.8</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.11540</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.05982</td>\n",
       "      <td>...</td>\n",
       "      <td>15.29</td>\n",
       "      <td>34.27</td>\n",
       "      <td>104.30</td>\n",
       "      <td>728.3</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.42340</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.08351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>10.80</td>\n",
       "      <td>9.71</td>\n",
       "      <td>68.77</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.05736</td>\n",
       "      <td>0.025310</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>...</td>\n",
       "      <td>11.60</td>\n",
       "      <td>12.02</td>\n",
       "      <td>73.66</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.04603</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.07699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>13.77</td>\n",
       "      <td>13.27</td>\n",
       "      <td>88.06</td>\n",
       "      <td>582.7</td>\n",
       "      <td>0.09198</td>\n",
       "      <td>0.06221</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.05912</td>\n",
       "      <td>...</td>\n",
       "      <td>14.67</td>\n",
       "      <td>16.93</td>\n",
       "      <td>94.17</td>\n",
       "      <td>661.1</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.03732</td>\n",
       "      <td>0.05802</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>0.06794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>11.54</td>\n",
       "      <td>10.72</td>\n",
       "      <td>73.73</td>\n",
       "      <td>409.1</td>\n",
       "      <td>0.08597</td>\n",
       "      <td>0.05969</td>\n",
       "      <td>0.013670</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.06100</td>\n",
       "      <td>...</td>\n",
       "      <td>12.34</td>\n",
       "      <td>12.87</td>\n",
       "      <td>81.23</td>\n",
       "      <td>467.8</td>\n",
       "      <td>0.1092</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.08324</td>\n",
       "      <td>0.04715</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>0.07434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16.13</td>\n",
       "      <td>17.88</td>\n",
       "      <td>107.00</td>\n",
       "      <td>807.2</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.15590</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.077520</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>0.06515</td>\n",
       "      <td>...</td>\n",
       "      <td>20.21</td>\n",
       "      <td>27.26</td>\n",
       "      <td>132.70</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.5804</td>\n",
       "      <td>0.52740</td>\n",
       "      <td>0.18640</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.12330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>13.85</td>\n",
       "      <td>17.21</td>\n",
       "      <td>88.44</td>\n",
       "      <td>588.7</td>\n",
       "      <td>0.08785</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.05890</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>23.58</td>\n",
       "      <td>100.30</td>\n",
       "      <td>725.9</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.08115</td>\n",
       "      <td>0.05104</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>12.67</td>\n",
       "      <td>17.30</td>\n",
       "      <td>81.25</td>\n",
       "      <td>489.9</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.07664</td>\n",
       "      <td>0.031930</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.1707</td>\n",
       "      <td>0.05984</td>\n",
       "      <td>...</td>\n",
       "      <td>13.71</td>\n",
       "      <td>21.10</td>\n",
       "      <td>88.70</td>\n",
       "      <td>574.4</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>0.05602</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.06888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>13.28</td>\n",
       "      <td>13.72</td>\n",
       "      <td>85.79</td>\n",
       "      <td>541.8</td>\n",
       "      <td>0.08363</td>\n",
       "      <td>0.08575</td>\n",
       "      <td>0.050770</td>\n",
       "      <td>0.028640</td>\n",
       "      <td>0.1617</td>\n",
       "      <td>0.05594</td>\n",
       "      <td>...</td>\n",
       "      <td>14.24</td>\n",
       "      <td>17.37</td>\n",
       "      <td>96.59</td>\n",
       "      <td>623.7</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.28660</td>\n",
       "      <td>0.09173</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.07320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "185        10.08         15.11           63.76      317.5          0.09267   \n",
       "190        14.22         23.12           94.37      609.9          0.10750   \n",
       "536        14.27         22.55           93.77      629.8          0.10380   \n",
       "166        10.80          9.71           68.77      357.6          0.09594   \n",
       "295        13.77         13.27           88.06      582.7          0.09198   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "313        11.54         10.72           73.73      409.1          0.08597   \n",
       "34         16.13         17.88          107.00      807.2          0.10400   \n",
       "125        13.85         17.21           88.44      588.7          0.08785   \n",
       "325        12.67         17.30           81.25      489.9          0.10280   \n",
       "384        13.28         13.72           85.79      541.8          0.08363   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "185           0.04695        0.001597             0.002404         0.1703   \n",
       "190           0.24130        0.198100             0.066180         0.2384   \n",
       "536           0.11540        0.146300             0.061390         0.1926   \n",
       "166           0.05736        0.025310             0.016980         0.1381   \n",
       "295           0.06221        0.010630             0.019170         0.1592   \n",
       "..                ...             ...                  ...            ...   \n",
       "313           0.05969        0.013670             0.008907         0.1833   \n",
       "34            0.15590        0.135400             0.077520         0.1998   \n",
       "125           0.06136        0.014200             0.011410         0.1614   \n",
       "325           0.07664        0.031930             0.021070         0.1707   \n",
       "384           0.08575        0.050770             0.028640         0.1617   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "185                 0.06048  ...         11.87          21.18   \n",
       "190                 0.07542  ...         15.74          37.18   \n",
       "536                 0.05982  ...         15.29          34.27   \n",
       "166                 0.06400  ...         11.60          12.02   \n",
       "295                 0.05912  ...         14.67          16.93   \n",
       "..                      ...  ...           ...            ...   \n",
       "313                 0.06100  ...         12.34          12.87   \n",
       "34                  0.06515  ...         20.21          27.26   \n",
       "125                 0.05890  ...         15.49          23.58   \n",
       "325                 0.05984  ...         13.71          21.10   \n",
       "384                 0.05594  ...         14.24          17.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "185            75.39       437.0            0.1521             0.1019   \n",
       "190           106.40       762.4            0.1533             0.9327   \n",
       "536           104.30       728.3            0.1380             0.2733   \n",
       "166            73.66       414.0            0.1436             0.1257   \n",
       "295            94.17       661.1            0.1170             0.1072   \n",
       "..               ...         ...               ...                ...   \n",
       "313            81.23       467.8            0.1092             0.1626   \n",
       "34            132.70      1261.0            0.1446             0.5804   \n",
       "125           100.30       725.9            0.1157             0.1350   \n",
       "325            88.70       574.4            0.1384             0.1212   \n",
       "384            96.59       623.7            0.1166             0.2685   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "185          0.00692               0.01042          0.2933   \n",
       "190          0.84880               0.17720          0.5166   \n",
       "536          0.42340               0.13620          0.2698   \n",
       "166          0.10470               0.04603          0.2090   \n",
       "295          0.03732               0.05802          0.2823   \n",
       "..               ...                   ...             ...   \n",
       "313          0.08324               0.04715          0.3390   \n",
       "34           0.52740               0.18640          0.4270   \n",
       "125          0.08115               0.05104          0.2364   \n",
       "325          0.10200               0.05602          0.2688   \n",
       "384          0.28660               0.09173          0.2736   \n",
       "\n",
       "     worst fractal dimension  \n",
       "185                  0.07697  \n",
       "190                  0.14460  \n",
       "536                  0.08351  \n",
       "166                  0.07699  \n",
       "295                  0.06794  \n",
       "..                       ...  \n",
       "313                  0.07434  \n",
       "34                   0.12330  \n",
       "125                  0.07182  \n",
       "325                  0.06888  \n",
       "384                  0.07320  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e645317-4915-4aba-a254-b6ad4c7b7f5f",
   "metadata": {},
   "source": [
    "##### Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffe78fa5-c038-4a12-9efc-94b3fcf2fda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e461108-bf31-4416-95f8-db3138fcc0dc",
   "metadata": {},
   "source": [
    "##### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df4e3350-8a66-4f85-a16e-caf2caef880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>20.94</td>\n",
       "      <td>23.56</td>\n",
       "      <td>138.90</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.16060</td>\n",
       "      <td>0.27120</td>\n",
       "      <td>0.13100</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.05898</td>\n",
       "      <td>...</td>\n",
       "      <td>25.58</td>\n",
       "      <td>27.00</td>\n",
       "      <td>165.30</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.3172</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.21050</td>\n",
       "      <td>0.3126</td>\n",
       "      <td>0.07849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>15.32</td>\n",
       "      <td>17.27</td>\n",
       "      <td>103.20</td>\n",
       "      <td>713.3</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.22840</td>\n",
       "      <td>0.24480</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.07596</td>\n",
       "      <td>...</td>\n",
       "      <td>17.73</td>\n",
       "      <td>22.66</td>\n",
       "      <td>119.80</td>\n",
       "      <td>928.8</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.11910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>12.16</td>\n",
       "      <td>18.03</td>\n",
       "      <td>78.29</td>\n",
       "      <td>455.3</td>\n",
       "      <td>0.09087</td>\n",
       "      <td>0.07838</td>\n",
       "      <td>0.02916</td>\n",
       "      <td>0.01527</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.06284</td>\n",
       "      <td>...</td>\n",
       "      <td>13.34</td>\n",
       "      <td>27.87</td>\n",
       "      <td>88.83</td>\n",
       "      <td>547.4</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.05690</td>\n",
       "      <td>0.2406</td>\n",
       "      <td>0.07729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>19.80</td>\n",
       "      <td>21.56</td>\n",
       "      <td>129.70</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>0.09383</td>\n",
       "      <td>0.13060</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.08691</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>25.73</td>\n",
       "      <td>28.64</td>\n",
       "      <td>170.30</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.3617</td>\n",
       "      <td>0.18200</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.08255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>11.84</td>\n",
       "      <td>18.94</td>\n",
       "      <td>75.51</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.08871</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.02669</td>\n",
       "      <td>0.01393</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.06057</td>\n",
       "      <td>...</td>\n",
       "      <td>13.30</td>\n",
       "      <td>24.99</td>\n",
       "      <td>85.22</td>\n",
       "      <td>546.3</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.06913</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.07993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>17.91</td>\n",
       "      <td>21.02</td>\n",
       "      <td>124.40</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.31890</td>\n",
       "      <td>0.11980</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>...</td>\n",
       "      <td>20.80</td>\n",
       "      <td>27.78</td>\n",
       "      <td>149.60</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.19640</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.11980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>12.45</td>\n",
       "      <td>16.41</td>\n",
       "      <td>82.85</td>\n",
       "      <td>476.7</td>\n",
       "      <td>0.09514</td>\n",
       "      <td>0.15110</td>\n",
       "      <td>0.15440</td>\n",
       "      <td>0.04846</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>...</td>\n",
       "      <td>13.78</td>\n",
       "      <td>21.03</td>\n",
       "      <td>97.82</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.4061</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.13420</td>\n",
       "      <td>0.3231</td>\n",
       "      <td>0.10340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>11.36</td>\n",
       "      <td>17.57</td>\n",
       "      <td>72.49</td>\n",
       "      <td>399.8</td>\n",
       "      <td>0.08858</td>\n",
       "      <td>0.05313</td>\n",
       "      <td>0.02783</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.05913</td>\n",
       "      <td>...</td>\n",
       "      <td>13.05</td>\n",
       "      <td>36.32</td>\n",
       "      <td>85.07</td>\n",
       "      <td>521.3</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.08698</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.07745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>15.10</td>\n",
       "      <td>16.39</td>\n",
       "      <td>99.58</td>\n",
       "      <td>674.5</td>\n",
       "      <td>0.11500</td>\n",
       "      <td>0.18070</td>\n",
       "      <td>0.11380</td>\n",
       "      <td>0.08534</td>\n",
       "      <td>0.2001</td>\n",
       "      <td>0.06467</td>\n",
       "      <td>...</td>\n",
       "      <td>16.11</td>\n",
       "      <td>18.33</td>\n",
       "      <td>105.90</td>\n",
       "      <td>762.6</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.14230</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>0.07779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "250        20.94         23.56          138.90     1364.0          0.10070   \n",
       "257        15.32         17.27          103.20      713.3          0.13350   \n",
       "480        12.16         18.03           78.29      455.3          0.09087   \n",
       "218        19.80         21.56          129.70     1230.0          0.09383   \n",
       "12         19.17         24.80          132.40     1123.0          0.09740   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "211        11.84         18.94           75.51      428.0          0.08871   \n",
       "400        17.91         21.02          124.40      994.0          0.12300   \n",
       "485        12.45         16.41           82.85      476.7          0.09514   \n",
       "410        11.36         17.57           72.49      399.8          0.08858   \n",
       "128        15.10         16.39           99.58      674.5          0.11500   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "250           0.16060         0.27120              0.13100         0.2205   \n",
       "257           0.22840         0.24480              0.12420         0.2398   \n",
       "480           0.07838         0.02916              0.01527         0.1464   \n",
       "218           0.13060         0.12720              0.08691         0.2094   \n",
       "12            0.24580         0.20650              0.11180         0.2397   \n",
       "..                ...             ...                  ...            ...   \n",
       "211           0.06900         0.02669              0.01393         0.1533   \n",
       "400           0.25760         0.31890              0.11980         0.2113   \n",
       "485           0.15110         0.15440              0.04846         0.2082   \n",
       "410           0.05313         0.02783              0.02100         0.1601   \n",
       "128           0.18070         0.11380              0.08534         0.2001   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "250                 0.05898  ...         25.58          27.00   \n",
       "257                 0.07596  ...         17.73          22.66   \n",
       "480                 0.06284  ...         13.34          27.87   \n",
       "218                 0.05581  ...         25.73          28.64   \n",
       "12                  0.07800  ...         20.96          29.94   \n",
       "..                      ...  ...           ...            ...   \n",
       "211                 0.06057  ...         13.30          24.99   \n",
       "400                 0.07115  ...         20.80          27.78   \n",
       "485                 0.07325  ...         13.78          21.03   \n",
       "410                 0.05913  ...         13.05          36.32   \n",
       "128                 0.06467  ...         16.11          18.33   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "250           165.30      2010.0            0.1211             0.3172   \n",
       "257           119.80       928.8            0.1765             0.4503   \n",
       "480            88.83       547.4            0.1208             0.2279   \n",
       "218           170.30      2009.0            0.1353             0.3235   \n",
       "12            151.70      1332.0            0.1037             0.3903   \n",
       "..               ...         ...               ...                ...   \n",
       "211            85.22       546.3            0.1280             0.1880   \n",
       "400           149.60      1304.0            0.1873             0.5917   \n",
       "485            97.82       580.6            0.1175             0.4061   \n",
       "410            85.07       521.3            0.1453             0.1622   \n",
       "128           105.90       762.6            0.1386             0.2883   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "250           0.6991               0.21050          0.3126   \n",
       "257           0.4429               0.22290          0.3258   \n",
       "480           0.1620               0.05690          0.2406   \n",
       "218           0.3617               0.18200          0.3070   \n",
       "12            0.3639               0.17670          0.3176   \n",
       "..               ...                   ...             ...   \n",
       "211           0.1471               0.06913          0.2535   \n",
       "400           0.9034               0.19640          0.3245   \n",
       "485           0.4896               0.13420          0.3231   \n",
       "410           0.1811               0.08698          0.2973   \n",
       "128           0.1960               0.14230          0.2590   \n",
       "\n",
       "     worst fractal dimension  \n",
       "250                  0.07849  \n",
       "257                  0.11910  \n",
       "480                  0.07729  \n",
       "218                  0.08255  \n",
       "12                   0.10230  \n",
       "..                       ...  \n",
       "211                  0.07993  \n",
       "400                  0.11980  \n",
       "485                  0.10340  \n",
       "410                  0.07745  \n",
       "128                  0.07779  \n",
       "\n",
       "[114 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b3d02-5c59-40e3-bf35-0610b18bcde0",
   "metadata": {},
   "source": [
    "##### Testing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a696a349-9b4a-4712-acb1-f076134618e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3d750",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9039a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.7098214285714286, 0.9444444444444444, 'X[22] <= 113.15\\ngini = 0.47\\nsamples = 455\\nvalue = [172, 283]'),\n",
       " Text(0.5625, 0.8333333333333334, 'X[27] <= 0.146\\ngini = 0.168\\nsamples = 303\\nvalue = [28, 275]'),\n",
       " Text(0.4392857142857143, 0.7222222222222222, 'X[23] <= 874.85\\ngini = 0.075\\nsamples = 280\\nvalue = [11, 269]'),\n",
       " Text(0.3357142857142857, 0.6111111111111112, 'X[27] <= 0.135\\ngini = 0.056\\nsamples = 276\\nvalue = [8, 268]'),\n",
       " Text(0.21428571428571427, 0.5, 'X[13] <= 38.605\\ngini = 0.03\\nsamples = 264\\nvalue = [4, 260]'),\n",
       " Text(0.11428571428571428, 0.3888888888888889, 'X[14] <= 0.003\\ngini = 0.016\\nsamples = 254\\nvalue = [2, 252]'),\n",
       " Text(0.05714285714285714, 0.2777777777777778, 'X[14] <= 0.003\\ngini = 0.245\\nsamples = 7\\nvalue = [1, 6]'),\n",
       " Text(0.02857142857142857, 0.16666666666666666, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(0.08571428571428572, 0.16666666666666666, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.17142857142857143, 0.2777777777777778, 'X[21] <= 33.27\\ngini = 0.008\\nsamples = 247\\nvalue = [1, 246]'),\n",
       " Text(0.14285714285714285, 0.16666666666666666, 'gini = 0.0\\nsamples = 234\\nvalue = [0, 234]'),\n",
       " Text(0.2, 0.16666666666666666, 'X[24] <= 0.14\\ngini = 0.142\\nsamples = 13\\nvalue = [1, 12]'),\n",
       " Text(0.17142857142857143, 0.05555555555555555, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 12]'),\n",
       " Text(0.22857142857142856, 0.05555555555555555, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.3142857142857143, 0.3888888888888889, 'X[27] <= 0.116\\ngini = 0.32\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " Text(0.2857142857142857, 0.2777777777777778, 'X[18] <= 0.016\\ngini = 0.198\\nsamples = 9\\nvalue = [1, 8]'),\n",
       " Text(0.2571428571428571, 0.16666666666666666, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.3142857142857143, 0.16666666666666666, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8]'),\n",
       " Text(0.34285714285714286, 0.2777777777777778, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.45714285714285713, 0.5, 'X[1] <= 20.24\\ngini = 0.444\\nsamples = 12\\nvalue = [4, 8]'),\n",
       " Text(0.42857142857142855, 0.3888888888888889, 'X[27] <= 0.139\\ngini = 0.198\\nsamples = 9\\nvalue = [1, 8]'),\n",
       " Text(0.4, 0.2777777777777778, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.45714285714285713, 0.2777777777777778, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8]'),\n",
       " Text(0.4857142857142857, 0.3888888888888889, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(0.5428571428571428, 0.6111111111111112, 'X[21] <= 22.94\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(0.5142857142857142, 0.5, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(0.5714285714285714, 0.5, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(0.6857142857142857, 0.7222222222222222, 'X[1] <= 17.995\\ngini = 0.386\\nsamples = 23\\nvalue = [17, 6]'),\n",
       " Text(0.6571428571428571, 0.6111111111111112, 'X[27] <= 0.181\\ngini = 0.375\\nsamples = 8\\nvalue = [2, 6]'),\n",
       " Text(0.6285714285714286, 0.5, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(0.6857142857142857, 0.5, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(0.7142857142857143, 0.6111111111111112, 'gini = 0.0\\nsamples = 15\\nvalue = [15, 0]'),\n",
       " Text(0.8571428571428571, 0.8333333333333334, 'X[1] <= 14.955\\ngini = 0.1\\nsamples = 152\\nvalue = [144, 8]'),\n",
       " Text(0.8, 0.7222222222222222, 'X[26] <= 0.361\\ngini = 0.48\\nsamples = 10\\nvalue = [4, 6]'),\n",
       " Text(0.7714285714285715, 0.6111111111111112, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(0.8285714285714286, 0.6111111111111112, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(0.9142857142857143, 0.7222222222222222, 'X[7] <= 0.028\\ngini = 0.028\\nsamples = 142\\nvalue = [140, 2]'),\n",
       " Text(0.8857142857142857, 0.6111111111111112, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(0.9428571428571428, 0.6111111111111112, 'X[23] <= 810.1\\ngini = 0.014\\nsamples = 141\\nvalue = [140, 1]'),\n",
       " Text(0.9142857142857143, 0.5, 'X[13] <= 24.01\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(0.8857142857142857, 0.3888888888888889, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(0.9428571428571428, 0.3888888888888889, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(0.9714285714285714, 0.5, 'gini = 0.0\\nsamples = 138\\nvalue = [138, 0]')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clfDTC = tree.DecisionTreeClassifier()\n",
    "clfDTC = clfDTC.fit(train_data, train_result)\n",
    "tree.plot_tree(clfDTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0344296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  3]\n",
      " [ 7 67]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction = clfDTC.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78b90998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88        40\n",
      "           1       0.96      0.91      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.92      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f3a6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9122807017543859\n",
      "Precision    : 0.9571428571428572\n",
      "Recall       : 0.9054054054054054\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ee407",
   "metadata": {},
   "source": [
    "ID3 ESTIMATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9c044bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from id3.id3 import Id3Estimator\n",
    "estimator = Id3Estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af26cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = estimator.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10da9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  5]\n",
      " [ 6 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86        40\n",
      "           1       0.93      0.92      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = estimator.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))\n",
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "915f9c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9035087719298246\n",
      "Precision    : 0.9315068493150684\n",
      "Recall       : 0.918918918918919\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c683d0-122f-436b-8cea-9b7ee860db97",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf951515-865e-4aba-a985-9cd419533cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(train_data)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0d69182-8e05-41e1-974f-1317e3dcae00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.26231643e+01, 1.85270255e+01, 8.15761473e+01, 5.01426062e+02,\n",
       "        9.42349575e-02, 9.08669122e-02, 6.38605864e-02, 3.38261388e-02,\n",
       "        1.77486402e-01, 6.32302833e-02, 3.01293768e-01, 1.19632068e+00,\n",
       "        2.13120482e+00, 2.37126261e+01, 7.07773088e-03, 2.33690425e-02,\n",
       "        2.89771244e-02, 1.05092380e-02, 2.05316034e-02, 3.71964108e-03,\n",
       "        1.41304079e+01, 2.46635127e+01, 9.25696601e+01, 6.27633711e+02,\n",
       "        1.29240680e-01, 2.26392181e-01, 2.26811329e-01, 9.26319292e-02,\n",
       "        2.84182720e-01, 8.33706232e-02],\n",
       "       [1.92943137e+01, 2.16262745e+01, 1.27766667e+02, 1.17394804e+03,\n",
       "        1.02015882e-01, 1.51273725e-01, 1.80083235e-01, 1.02182255e-01,\n",
       "        1.92276471e-01, 6.09223529e-02, 7.28532353e-01, 1.20839902e+00,\n",
       "        5.11998039e+00, 9.27722549e+01, 6.65075490e-03, 3.24871275e-02,\n",
       "        4.24989216e-02, 1.54214510e-02, 1.99603922e-02, 3.92386275e-03,\n",
       "        2.36018627e+01, 2.87838235e+01, 1.57843137e+02, 1.73599020e+03,\n",
       "        1.41484706e-01, 3.62407451e-01, 4.52894118e-01, 1.92672745e-01,\n",
       "        3.13213725e-01, 8.66858824e-02]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da1b5d22-e787-47e3-9cb8-dbae41c09b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 12]\n",
      " [ 0 74]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction = kmeans.fit_predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c551f37-6797-4d8d-8e7e-ccc7d552e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        40\n",
      "           1       0.86      1.00      0.92        74\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.93      0.85      0.87       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1901300a-cecb-4c12-ad25-0b5fb94b86a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.8947368421052632\n",
      "Precision    : 0.8604651162790697\n",
      "Recall       : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbce2ec-447f-4670-a87b-432ffb635925",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45c37e62-992b-4278-8378-e9d99eef1d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47ddf801-6f9a-46cf-9d91-a685443230e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  4]\n",
      " [ 2 72]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction=logreg.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fecc397b-1300-4489-9e2a-1db453908ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        40\n",
      "           1       0.95      0.97      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25e230e7-1e88-43ce-96bb-b15bb0da15fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9473684210526315\n",
      "Precision    : 0.9473684210526315\n",
      "Recall       : 0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc299600-a729-4981-ab38-a9d4fcc27911",
   "metadata": {},
   "source": [
    "#### Neural Network MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da354644-d8cd-4189-8343-bdb63b25d7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=300, random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpc = MLPClassifier(random_state=1, max_iter=300, solver='lbfgs')\n",
    "mlpc.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb1ed855-b450-4de4-85cc-0c1e98917e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  4]\n",
      " [ 2 72]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction=logreg.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64da07e7-1e5d-4a08-8d7b-58626ebf85cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        40\n",
      "           1       0.95      0.97      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d469e18e-6fb1-462a-bf31-66b820ab7c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9473684210526315\n",
      "Precision    : 0.9473684210526315\n",
      "Recall       : 0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f99bc0",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6fe58d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "\n",
    "clfSVM = svm.SVC()\n",
    "clfSVM.fit(train_data, train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51ae82e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  6]\n",
      " [ 2 72]]\n"
     ]
    }
   ],
   "source": [
    "prediction = clfSVM.predict(test_data)\n",
    "print(metrics.confusion_matrix(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ee312d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89        40\n",
      "           1       0.92      0.97      0.95        74\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_result, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "834384b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.9298245614035088\n",
      "Precision    : 0.9230769230769231\n",
      "Recall       : 0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy     : {metrics.accuracy_score(test_result, prediction)}\")\n",
    "print(f\"Precision    : {metrics.precision_score(test_result, prediction)}\")\n",
    "print(f\"Recall       : {metrics.recall_score(test_result, prediction)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
